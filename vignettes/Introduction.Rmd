---
title: "Introduction to cregg"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: false
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{Introduction to cregg}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This vignette provides an introduction to **cregg** a package for analyzing and visualizing the results of conjoint experiments, which are factorial discrete choice experiments that are increasingly popular in the political and social sciences for studying decision making and preferences over multidimensional issues. cregg provides functionality that is useful for analyzing and otherwise examining data from these designs, namely:

 - Estimation of average marginal component effects (AMCEs) for fully randomized conjoint designs and munging of AMCE estimates into tidy data frames, via `amce()`
 - Calculation of marginal means (MMs) for conjoint designs and munging them into tidy data frames via `mm()`
 - Tabulation of display frequencies of feature attributes via `freqs()` and cross-tabulation of feature restrictions using `props()`
 - Diagnostics to assess preference heterogeneity, including an omnibus statstical test (`cj_anova()`) and tidying of differences in AMCEs across subgroups (`amce_diffs()`)
 - Diagnostics to choose feature reference categories, via `amce_by_reference()`
 - **ggplot2**-based visualizations of AMCEs and MMs, via `plot()` methods for all of the above

The package takes its name from the surname of a famous White House Press Secretary.

The main selling point of cregg is simplicity of implementation and - unlike the [cjoint](https://cran.r-project.org/package=cjoint) package - cregg tries to follow tidy data principles throughout and provides a formula-based interface that meshes well with the underlying [**survey**](https://cran.r-project.org/package=survey)-based effect estimation API. Thus the response from any function is a tidy data frame that can easily be stacked with others (e.g., for computing AMCEs for subsets of respondents and then producing a facetted or grouped visualization). It also tries to take better advantage of data preprocessing steps by:

 - Using factor base levels rather than trying to set baseline levels atomically
 - Using "label" attributes on variables to provide pretty printing

Additionally all functions have arguments in data-formula order, making it simple to pipe into them via `%>%`.

Contributions and feedback are welcome on [GitHub](https://github.com/leeper/cregg/issues).

## Code Examples


```{r opts, echo=FALSE}
options(width = 120)
knitr::opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = TRUE, size="small", fig.width = 10, fig.height = 10)
```

The package includes an example conjoint dataset (borrowed and lightly modified from the [cjoint](https://cran.r-project.org/package=cjoint) package), which is used here and and in examples:

```{r load}
library("cregg")
data("hainmueller")
```

The package provides straightforward calculation and visualization of descriptive marginal means (MMs). These represent the mean outcome across all appearances of a particular conjoint feature level, averaging across all levels of all other features. In forced choice conjoint designs, MMs by definition average 0.5 with values above 0.5 indicating features that increase profile favorability and values below 0.5 indicating features that decrease profile favorability. For continuous outcomes, AMMs can take any value in the full range of the outcome. Calculation of MMs entails no modelling assumptions and are therefore simply descriptive quantities of interest:

```{r mmplot}
# descriptive plotting
f1 <- ChosenImmigrant ~ Gender + Education + LanguageSkills + 
       CountryOfOrigin + Job + JobExperience + JobPlans + 
       ReasonForApplication + PriorEntry
plot(mm(hainmueller, f1, id = ~ CaseID), vline = 0.5)
```

cregg functions use `attributes(feature)$label` to provide pretty printing of feature labels, so that variable names can be arbitrary. These can be overwritten using the `feature_labels` argument to override these settings. Feature levels are always deduced from the `levels()` of righthand-side variables in the model specification. All variables should be factors with levels in desired display order. Similarly, the plotted order of features is given by the order of terms in the RHS formula unless overridden by the order of variable names given in `feature_order`.

A more common analytic approach for conjoints is to estimate average marginal component effects (AMCEs) using some form of regression analysis. cregg uses `glm()` and `svyglm()` to perform estimation and [margins](https://cran.r-project.org/package=margins) to generate average marginal effect estimates. Designs can be specified with any interactions between conjoint features but only AMCEs are returned. (No functionality is provided at the moment for explict estimation of feature interaction effects.) Just like for `mm()`, the output of `cj()` (or its alias, `amce()`) is a tidy data frame:

```{r amce}
# estimation
amces <- cj(hainmueller, f1, id = ~ CaseID)
head(amces[c("feature", "level", "estimate", "std.error")], 20L)
```

This makes it very easy to modify, combine, print, etc. the resulting output. It also makes it easy to visualize using ggplot2. A convenience visualization function is provided:

```{r plot_amce}
# plotting of AMCEs
plot(amces)
```

## Subgroup Analyis

The high-level `cj()` provides some convenience functionality for examining results across subgroups of respondents. This can be useful for splitting results by subgroups or for diagnostics. For example, Hainmueller et al. were interested in result by respondent ethnocentrism. We can create a median split on the ethnocentrism variable and plot marginal means for the two groups:

```{r ethnocentrism_split}
hainmueller$ethno_cut <-
  factor(hainmueller$ethnocentrism > median(hainmueller$ethnocentrism, na.rm = TRUE),
         labels = c("high", "low"))
plot(cj(hainmueller, ChosenImmigrant ~ CountryOfOrigin + LanguageSkills,
        id = ~CaseID, by = ~ ethno_cut, estimate = "mm"),
     group = "ethno_cut", vline = 0.5)
```

Strikingly the results are quite similar for the two subgroup.

## Diagnostics

The package provides a number of diagnostic fucnctions. 

### Display Frequencies and Proportions

For example, to check display frequencies of conjoint features (to ensure equal - or unequal - display frequency):

```{r plot_freqs}
# plotting of display frequencies
plot(freqs(hainmueller, f1, id = ~ CaseID))
```

As can be clear in the above, constraints were imposed in the original study on the allowed combinations of `Job` and `Education` and also on combinations of `CountryOfOrigin` and `ReasonForApplication`. The `props()` function provides tidy proportions tables to quickly 

```{r table_freqs}
subset(props(hainmueller, ~ Job + Education, id = ~ CaseID), Proportion == 0)
subset(props(hainmueller, ~ CountryOfOrigin + ReasonForApplication, id = ~ CaseID), Proportion == 0)
```

So that it is possible to very the design was implemented as intended or to perform further subgroup analyses.

### Balance Testing

The main `amce()` and `mm()` functions can also be used for balance testing. Rather than comparing outcomes across features levels, we will compare a covariate across feature levels. Both approaches will give a similar result:

```{r balance_testing}
plot(mm(hainmueller,
        ethnocentrism ~ Job + Education + CountryOfOrigin + ReasonForApplication,
        id = ~ CaseID),
     xlim = range(hainmueller$ethnocentrism, na.rm = TRUE),
     vline = mean(hainmueller$ethnocentrism, na.rm = TRUE))
```
Given that confidence intervals for each feature hover closely around the grand mean, there is little reason to believe that imbalance is a problem. The same analysis could be performed using `amce()`.

### Carryover Testing

The high-level functionality of `cj()` from earlier for performing subgroup analyses can also be used for testing carryover problems.

```{r carryovers}
plot(cj(hainmueller, f1, id = ~CaseID, by = ~ contest_no, estimate = "mm"),
     group = "contest_no", vline = 0.5)
```

Here marginal means are shown separately for each "contest number" (first, second, third, etc.) from the study. As should be quite visually clear, there are no obvious patterns wherein a given feature generates consistently more or less positive rating based upon the order of the rating tasks.

### Left/Right Preferences

The same basic approach can be used to evaluate whether there is, for example, any preference for the lefthand or righthand profile (in a two-profile design):

```{r leftright}
plot(cj(hainmueller, f1, id = ~CaseID, by = ~ profile, estimate = "mm"),
     group = "profile", vline = 0.5)
```

Again, in this example there are no obvious concerns generated form the diagnostic.

### Reference Group Selection

Reference categories for AMCEs are often arbitrary and can affect intuitions about results, so the package also provides a diagnostic tool for helping to decide on an appropriate reference category:

```{r amce_diagnostic}
amce_diagnostic <- amce_by_reference(hainmueller, ChosenImmigrant ~ LanguageSkills, ~LanguageSkills, id = ~ CaseID)
plot(amce_diagnostic)
```

While the reference category has no meaningful bearing on estimation, it can affect inferences especially when subgroups are compared. For this reason, it can be useful to assess the substantive inferences from difference reference categories alongside any subgroup analysis. To provide simple subgroup analyses, the `cj()` function provides a `by` argument to iterate over subsets of `data` and calculate AMCEs or MMs on each subgroup.

For example, we may want to ensure that there are no substantial variations in preferences within-respondents across multiple conjoint decision tasks:

```{r mm_by}
mm_by <- cj(hainmueller, ChosenImmigrant ~ Gender + Education + LanguageSkills,
            id = ~ CaseID, estimate = "mm", by = ~ contest_no)
plot(mm_by, group = "contest_no", vline = 0.5)
```

A more formal test of these differences is provided by a nested model comparison test:

```{r cj_anova}
cj_anova(hainmueller, ChosenImmigrant ~ Gender + Education + LanguageSkills, by = ~ contest_no)
```

which provides a test of whether any of the interactions between the `by` variable and feature levels differ from zero.

And, finally, while it is increasingly common to present grouped dot-and-whisker charts as comparisons of subgroup AMCEs, that comparison can be misleading of preferences differ substantially in the reference category. When that occurs, similar AMCEs do not necessarily mean similar preferences; this is a subtle distinction that must be respected when engaging in *descriptive* as opposed to *causal* interpretation of conjoint results.

For example, we might want to understand differences in preferences by ethnocentrism, which can most clearly be seen in a subgroup MM plot:

```{r conditioanl_mms}
hainmueller$ethnosplit <- cut(hainmueller$ethnocentrism, 2)
x <- cj(na.omit(hainmueller), f1, id = ~ CaseID, estimate = "mm", by = ~ ethnosplit)
plot(x, group = "ethnosplit", vline = 0.5)
```

But if we want to interpret differences in the sizes of AMCEs (rather than descriptive differences in preferences), we might be inclined to design a similar visualization, replacing MMs with AMCEs. But in such cases, we cannot comment on the descriptive similarity in preferences across subgroups only the heterogeneity in causal effects of feature variations. To make (dis)similarity explicit, such visualizations should include an explicit test of differences in effect sizes. Facetting works well:

```{r conditional_amces}
# calculate conditional AMCEs
amces <- cj(na.omit(hainmueller), ChosenImmigrant ~ Gender + Education + LanguageSkills,
            id = ~ CaseID, estimate = "amce", by = ~ ethnosplit)
diffs <- cj(na.omit(hainmueller), ChosenImmigrant ~ Gender + Education + LanguageSkills,
            id = ~ CaseID, estimate = "diff", by = ~ ethnosplit)
stacked <- rbind(amces[!names(amces) %in% c("z", "p")], diffs[!names(diffs) %in% c("t", "p")])
plot(stacked) + ggplot2::facet_wrap(~BY, ncol = 3L)
```

But again, this plot showcases differences in conjoint effect sizes (AMCEs) not descriptive differences in underlying preferences.

